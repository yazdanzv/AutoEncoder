{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we load the data and do the pre-processing on it \n",
    "1. check if there is any NULL in the dataset (Because it is the MNIST dataset and it is popular we did not check this part)\n",
    "2. normalize the dataset with z-score and transfer the dataset to the new space with the mean of zero and the standard deviation of 1\n",
    "(Normalizing is not necessary in this project because all the features are in the same range from 0 to 255 but we do not do it here because it cause a problem in the fiting of the autoencoder and it needs integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load the Data Set\n",
    "data_labeled_train = pd.read_csv('labeled_train_set.csv')\n",
    "data_labeled_test = pd.read_csv('test_set.csv')\n",
    "data_unlabeled_train = pd.read_csv('unlabeled_train_set.csv')\n",
    "\n",
    "# Conver the Data Set to Numpy Array and Spliting Labels and Features\n",
    "X_train_labeled = data_labeled_train.iloc[: , 1:].values\n",
    "y_train_labeled = data_labeled_train.iloc[: , 0].values\n",
    "X_test_labeled = data_labeled_test.iloc[: , 1:].values\n",
    "y_test_labeled = data_labeled_test.iloc[: , 0].values\n",
    "X_train_unlabeled = data_unlabeled_train.iloc[:, :].values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build an Auto Encoder and use it for Feature Selection and by that Reduce the dimentionality of the data\n",
    "We are going to implement it in 5 layers: \n",
    "1. Input Layer\n",
    "2. 3 Hidden Layers (128 , 16, 128)\n",
    "3. Output Layer\n",
    "So now it is obvious how the architecture of our Encoder and also Decoder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "71/71 [==============================] - 4s 18ms/step - loss: -1308892.3750 - val_loss: -8596151.0000\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: -90018432.0000 - val_loss: -298728128.0000\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: -997779712.0000 - val_loss: -2302154496.0000\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - 1s 21ms/step - loss: -4949274624.0000 - val_loss: -9228468224.0000\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: -15920336896.0000 - val_loss: -25988585472.0000\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: -39345938432.0000 - val_loss: -58876444672.0000\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: -81976680448.0000 - val_loss: -115302137856.0000\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -151399907328.0000 - val_loss: -203593842688.0000\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -256311951360.0000 - val_loss: -333083344896.0000\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: -406355345408.0000 - val_loss: -515594551296.0000\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: -614770671616.0000 - val_loss: -764079636480.0000\n",
      "Epoch 12/50\n",
      "71/71 [==============================] - 1s 19ms/step - loss: -892664938496.0000 - val_loss: -1089937473536.0000\n",
      "Epoch 13/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -1251211739136.0000 - val_loss: -1505550270464.0000\n",
      "Epoch 14/50\n",
      "71/71 [==============================] - 1s 18ms/step - loss: -1702898696192.0000 - val_loss: -2021918113792.0000\n",
      "Epoch 15/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: -2260463517696.0000 - val_loss: -2652830695424.0000\n",
      "Epoch 16/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: -2934838919168.0000 - val_loss: -3412572504064.0000\n",
      "Epoch 17/50\n",
      "71/71 [==============================] - 1s 21ms/step - loss: -3739786412032.0000 - val_loss: -4312565809152.0000\n",
      "Epoch 18/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -4688960815104.0000 - val_loss: -5364180320256.0000\n",
      "Epoch 19/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: -5793108197376.0000 - val_loss: -6587056390144.0000\n",
      "Epoch 20/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: -7068895412224.0000 - val_loss: -7988164165632.0000\n",
      "Epoch 21/50\n",
      "71/71 [==============================] - 1s 19ms/step - loss: -8526786199552.0000 - val_loss: -9586747637760.0000\n",
      "Epoch 22/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -10178707587072.0000 - val_loss: -11390450401280.0000\n",
      "Epoch 23/50\n",
      "71/71 [==============================] - 1s 19ms/step - loss: -12036310302720.0000 - val_loss: -13407696715776.0000\n",
      "Epoch 24/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: -14115259023360.0000 - val_loss: -15660831735808.0000\n",
      "Epoch 25/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: -16425113616384.0000 - val_loss: -18157976682496.0000\n",
      "Epoch 26/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -18980100112384.0000 - val_loss: -20912596320256.0000\n",
      "Epoch 27/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: -21794413084672.0000 - val_loss: -23938937651200.0000\n",
      "Epoch 28/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: -24875987107840.0000 - val_loss: -27255369629696.0000\n",
      "Epoch 29/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: -28240695525376.0000 - val_loss: -30856003452928.0000\n",
      "Epoch 30/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: -31896765464576.0000 - val_loss: -34768959832064.0000\n",
      "Epoch 31/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -35858992332800.0000 - val_loss: -38999695556608.0000\n",
      "Epoch 32/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -40145982062592.0000 - val_loss: -43565409370112.0000\n",
      "Epoch 33/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: -44759531913216.0000 - val_loss: -48482438086656.0000\n",
      "Epoch 34/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: -49714477137920.0000 - val_loss: -53749775073280.0000\n",
      "Epoch 35/50\n",
      "71/71 [==============================] - 1s 21ms/step - loss: -55018291986432.0000 - val_loss: -59386458275840.0000\n",
      "Epoch 36/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -60688609312768.0000 - val_loss: -65393955700736.0000\n",
      "Epoch 37/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: -66730802020352.0000 - val_loss: -71798615965696.0000\n",
      "Epoch 38/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: -73160573583360.0000 - val_loss: -78617321144320.0000\n",
      "Epoch 39/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -79990192340992.0000 - val_loss: -85829317820416.0000\n",
      "Epoch 40/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -87236313874432.0000 - val_loss: -93484719538176.0000\n",
      "Epoch 41/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: -94898258706432.0000 - val_loss: -101585355014144.0000\n",
      "Epoch 42/50\n",
      "71/71 [==============================] - 1s 19ms/step - loss: -103006611701760.0000 - val_loss: -110151163969536.0000\n",
      "Epoch 43/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -111559460257792.0000 - val_loss: -119152031301632.0000\n",
      "Epoch 44/50\n",
      "71/71 [==============================] - 1s 18ms/step - loss: -120569219514368.0000 - val_loss: -128635948236800.0000\n",
      "Epoch 45/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: -130050720530432.0000 - val_loss: -138605758513152.0000\n",
      "Epoch 46/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -140004768612352.0000 - val_loss: -149095024951296.0000\n",
      "Epoch 47/50\n",
      "71/71 [==============================] - 2s 21ms/step - loss: -150454667313152.0000 - val_loss: -160084772519936.0000\n",
      "Epoch 48/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: -161418393419776.0000 - val_loss: -171605384757248.0000\n",
      "Epoch 49/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -172893019308032.0000 - val_loss: -183666374344704.0000\n",
      "Epoch 50/50\n",
      "71/71 [==============================] - 1s 21ms/step - loss: -184888074436608.0000 - val_loss: -196236518883328.0000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Implimenting the Auto Encoder with the architecture we talked about\n",
    "\n",
    "# Defining the Input Image dimention\n",
    "input_image = keras.Input(shape=(784,))\n",
    "\n",
    "# Define the Encoder\n",
    "encoded = layers.Dense(128, activation='relu')(input_image)\n",
    "encoded = layers.Dense(16, activation='relu')(encoded)\n",
    "\n",
    "# Build the Encoder\n",
    "encoder = keras.Model(input_image, encoded)\n",
    "\n",
    "# Define the Decoder \n",
    "encoded_input = keras.Input(shape=(16,))\n",
    "decoded = layers.Dense(128, activation='relu')(encoded_input)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "# Build the Decoder \n",
    "decoder = keras.Model(encoded_input, decoded)\n",
    "\n",
    "# Build the Auto Encoder\n",
    "auto_encoder = keras.Model(input_image, decoder(encoder(input_image)))\n",
    "\n",
    "# Compile the Auto Encoder\n",
    "auto_encoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "\n",
    "# Fit the Data on our Auto Encoder\n",
    "log = auto_encoder.fit(X_train_labeled, X_train_labeled, epochs=50, batch_size=256,\n",
    "shuffle=True, validation_data=(X_test_labeled, X_test_labeled))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Fitting of the Auto Encoder is done, we encode the data set with it (reduce its dimentionality to 16)\n",
    "P.S. I decide to reduce the dimentionality of the unlabeled data and then implement clustring algorithm on it to decrease the time of the running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "1313/1313 [==============================] - 3s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "encoded_X_train_labeled = encoder.predict(X_train_labeled)\n",
    "encoded_X_test_labeled = encoder.predict(X_test_labeled)\n",
    "encoded_X_train_unlabeled = encoder.predict(X_train_unlabeled)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the MLP model, I want to cluster the unlabeled data\n",
    "Clustring Algorithm : K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 4 4 ... 3 6 7]\n",
      "42000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Build the Model\n",
    "k_means = KMeans(n_clusters=10)\n",
    "\n",
    "# Fit Model on the Unlabeled Data\n",
    "k_means.fit(encoded_X_train_unlabeled)\n",
    "\n",
    "# Get the Labels\n",
    "labels = np.array(k_means.labels_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-processing \n",
    "After the clustering we have to know that which lable correspond to which number from 0 to 9,\n",
    "So I decide to find 1 instance from all of the labels and find their index in the unlabeled dataset that is not encoded because i've saved it for now, I could give their 16 features to decoder that I have built previously but I have the previous version of the dataset so I don't do that and at teh end visually Determine this thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 13, 14, 16, 36, 108, 113, 114, 118, 129]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16 166 253 253 255\n",
      " 253 253 253 192 141 141 141  79  22   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  29 252 252 252 253 252 252 252 253 252 252 252 253\n",
      " 234  38   0   0   0   0   0   0   0   0   0   0   0   0   0  19 224 252\n",
      " 252 253 252 252 252 253 252 252 252 253 252  94   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  51 214 156 252 252 140 139 139 190 253 252 252\n",
      " 252 253 177  94   0   0   0   0   0   0   0   0   0   0   0  48 241 255\n",
      " 253  69   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 160 252 253 252 205  13   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 197\n",
      " 252 253 252 130   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  51 246 252 253 202   6   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 169 253 253 254 253 165 191 141 141 141 141  79  29   7   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 169 252 252 253 252 252 252 253\n",
      " 252 252 252 253 252 187  19   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0 169 252 252 253 252 252 252 253 252 252 252 253 252 252 116   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  44 228 252 253 252 252\n",
      " 252 253 252 252 252 253 252 252 190   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  29 253 253\n",
      " 253 114   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  29 252 252 252 113   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 104 197  38   0   0   0   0   0   0   0 117\n",
      " 252 252 252 113   0   0   0   0   0   0   0   0   0   0   0   0 101 246\n",
      " 252 113   0   0   0   0   0   0 101 241 252 252 252 113   0   0   0   0\n",
      "   0   0   0   0   0   0   0  29 253 253 253 254 253 253 203 141 141 229\n",
      " 253 254 253 253 190   0   0   0   0   0   0   0   0   0   0   0   0  29\n",
      " 252 252 252 253 252 252 252 253 252 252 252 253 252 208  59   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   7 149 252 252 253 252 252 252 253\n",
      " 252 252 252 253 196  37   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   7  28  28  28 103 139 240 253 252 252 202 128   9   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Get instance from all of the labels\n",
    "instances = []\n",
    "index = 0\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == index:\n",
    "        instances.append(i)\n",
    "        index += 1\n",
    "print(instances)\n",
    "\n",
    "# Get their features\n",
    "instances_features = []\n",
    "for i in range(len(instances)):\n",
    "    instances_features.append(X_train_unlabeled[instances[i]])\n",
    "print(instances_features[0])\n",
    "print(len(instances_features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Pillow Library, I convert the matrixes to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
