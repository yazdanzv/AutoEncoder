{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we load the data and do the pre-processing on it \n",
    "1. check if there is any NULL in the dataset (Because it is the MNIST dataset and it is popular we did not check this part)\n",
    "2. normalize the dataset with z-score and transfer the dataset to the new space with the mean of zero and the standard deviation of 1\n",
    "(Normalizing is not necessary in this project because all the features are in the same range from 0 to 255 but we do not do it here because it cause a problem in the fiting of the autoencoder and it needs integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load the Data Set\n",
    "data_labeled_train = pd.read_csv('labeled_train_set.csv')\n",
    "data_labeled_test = pd.read_csv('test_set.csv')\n",
    "data_unlabeled_train = pd.read_csv('unlabeled_train_set.csv')\n",
    "\n",
    "# Conver the Data Set to Numpy Array and Spliting Labels and Features\n",
    "X_train_labeled = data_labeled_train.iloc[: , 1:].values\n",
    "y_train_labeled = data_labeled_train.iloc[: , 0].values\n",
    "X_test_labeled = data_labeled_test.iloc[: , 1:].values\n",
    "y_test_labeled = data_labeled_test.iloc[: , 0].values\n",
    "X_train_unlabeled = data_unlabeled_train.iloc[:, :].values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build an Auto Encoder and use it for Feature Selection and by that Reduce the dimentionality of the data\n",
    "We are going to implement it in 5 layers: \n",
    "1. Input Layer\n",
    "2. 3 Hidden Layers (128 , 16, 128)\n",
    "3. Output Layer\n",
    "So now it is obvious how the architecture of our Encoder and also Decoder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "71/71 [==============================] - 3s 30ms/step - loss: -1250878.6250 - val_loss: -8148861.5000\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 2s 25ms/step - loss: -84777888.0000 - val_loss: -282595808.0000\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - 1s 18ms/step - loss: -944950528.0000 - val_loss: -2164544000.0000\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - 2s 23ms/step - loss: -4638723072.0000 - val_loss: -8611849216.0000\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - 2s 26ms/step - loss: -14802934784.0000 - val_loss: -24157425664.0000\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - 1s 20ms/step - loss: -36543922176.0000 - val_loss: -54645645312.0000\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - 1s 21ms/step - loss: -76108349440.0000 - val_loss: -107067572224.0000\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - 2s 27ms/step - loss: -140604850176.0000 - val_loss: -189103734784.0000\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - 1s 19ms/step - loss: -237886767104.0000 - val_loss: -309399879680.0000\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -376706334720.0000 - val_loss: -477054107648.0000\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - 2s 25ms/step - loss: -566304768000.0000 - val_loss: -701155835904.0000\n",
      "Epoch 12/50\n",
      "71/71 [==============================] - 2s 23ms/step - loss: -816095166464.0000 - val_loss: -993282162688.0000\n",
      "Epoch 13/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -1135793012736.0000 - val_loss: -1362048319488.0000\n",
      "Epoch 14/50\n",
      "71/71 [==============================] - 1s 18ms/step - loss: -1536035913728.0000 - val_loss: -1817471614976.0000\n",
      "Epoch 15/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -2026704338944.0000 - val_loss: -2372776755200.0000\n",
      "Epoch 16/50\n",
      "71/71 [==============================] - 2s 25ms/step - loss: -2618215104512.0000 - val_loss: -3036958687232.0000\n",
      "Epoch 17/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -3322233225216.0000 - val_loss: -3821223018496.0000\n",
      "Epoch 18/50\n",
      "71/71 [==============================] - 2s 25ms/step - loss: -4147588366336.0000 - val_loss: -4736671547392.0000\n",
      "Epoch 19/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: -5105439473664.0000 - val_loss: -5793579532288.0000\n",
      "Epoch 20/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -6208057507840.0000 - val_loss: -7003451162624.0000\n",
      "Epoch 21/50\n",
      "71/71 [==============================] - 2s 28ms/step - loss: -7462853804032.0000 - val_loss: -8376003067904.0000\n",
      "Epoch 22/50\n",
      "71/71 [==============================] - 2s 25ms/step - loss: -8882856394752.0000 - val_loss: -9922157740032.0000\n",
      "Epoch 23/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -10480364027904.0000 - val_loss: -11662475132928.0000\n",
      "Epoch 24/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -12262443057152.0000 - val_loss: -13589806055424.0000\n",
      "Epoch 25/50\n",
      "71/71 [==============================] - 1s 19ms/step - loss: -14237535567872.0000 - val_loss: -15725069598720.0000\n",
      "Epoch 26/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -16419718692864.0000 - val_loss: -18076181463040.0000\n",
      "Epoch 27/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -18820131454976.0000 - val_loss: -20650320199680.0000\n",
      "Epoch 28/50\n",
      "71/71 [==============================] - 2s 25ms/step - loss: -21445377785856.0000 - val_loss: -23477721497600.0000\n",
      "Epoch 29/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -24308868972544.0000 - val_loss: -26540458901504.0000\n",
      "Epoch 30/50\n",
      "71/71 [==============================] - 2s 27ms/step - loss: -27417571753984.0000 - val_loss: -29862127468544.0000\n",
      "Epoch 31/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -30784668827648.0000 - val_loss: -33463145070592.0000\n",
      "Epoch 32/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -34415321284608.0000 - val_loss: -37341603299328.0000\n",
      "Epoch 33/50\n",
      "71/71 [==============================] - 2s 25ms/step - loss: -38326207774720.0000 - val_loss: -41501841162240.0000\n",
      "Epoch 34/50\n",
      "71/71 [==============================] - 1s 18ms/step - loss: -42529529528320.0000 - val_loss: -45963724980224.0000\n",
      "Epoch 35/50\n",
      "71/71 [==============================] - 2s 25ms/step - loss: -47036506308608.0000 - val_loss: -50749920772096.0000\n",
      "Epoch 36/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -51847293304832.0000 - val_loss: -55850949410816.0000\n",
      "Epoch 37/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -56977262641152.0000 - val_loss: -61293583138816.0000\n",
      "Epoch 38/50\n",
      "71/71 [==============================] - 2s 26ms/step - loss: -62430407294976.0000 - val_loss: -67073082392576.0000\n",
      "Epoch 39/50\n",
      "71/71 [==============================] - 2s 23ms/step - loss: -68225568079872.0000 - val_loss: -73176075730944.0000\n",
      "Epoch 40/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: -74359892869120.0000 - val_loss: -79667339984896.0000\n",
      "Epoch 41/50\n",
      "71/71 [==============================] - 2s 23ms/step - loss: -80857440190464.0000 - val_loss: -86531318480896.0000\n",
      "Epoch 42/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -87717794807808.0000 - val_loss: -93765050040320.0000\n",
      "Epoch 43/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -94950712672256.0000 - val_loss: -101391024521216.0000\n",
      "Epoch 44/50\n",
      "71/71 [==============================] - 2s 25ms/step - loss: -102571511382016.0000 - val_loss: -109400408719360.0000\n",
      "Epoch 45/50\n",
      "71/71 [==============================] - 2s 23ms/step - loss: -110583236001792.0000 - val_loss: -117843962101760.0000\n",
      "Epoch 46/50\n",
      "71/71 [==============================] - 2s 25ms/step - loss: -119002948960256.0000 - val_loss: -126705544986624.0000\n",
      "Epoch 47/50\n",
      "71/71 [==============================] - 2s 22ms/step - loss: -127839147917312.0000 - val_loss: -135991650156544.0000\n",
      "Epoch 48/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: -137092210360320.0000 - val_loss: -145727636373504.0000\n",
      "Epoch 49/50\n",
      "71/71 [==============================] - 2s 25ms/step - loss: -146780591226880.0000 - val_loss: -155887482175488.0000\n",
      "Epoch 50/50\n",
      "71/71 [==============================] - 2s 24ms/step - loss: -156910724579328.0000 - val_loss: -166519203954688.0000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Implimenting the Auto Encoder with the architecture we talked about\n",
    "\n",
    "# Defining the Input Image dimention\n",
    "input_image = keras.Input(shape=(784,))\n",
    "\n",
    "# Define the Encoder\n",
    "encoded = layers.Dense(128, activation='relu')(input_image)\n",
    "encoded = layers.Dense(16, activation='relu')(encoded)\n",
    "\n",
    "# Build the Encoder\n",
    "encoder = keras.Model(input_image, encoded)\n",
    "\n",
    "# Define the Decoder \n",
    "encoded_input = keras.Input(shape=(16,))\n",
    "decoded = layers.Dense(128, activation='relu')(encoded_input)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "# Build the Decoder \n",
    "decoder = keras.Model(encoded_input, decoded)\n",
    "\n",
    "# Build the Auto Encoder\n",
    "auto_encoder = keras.Model(input_image, decoder(encoder(input_image)))\n",
    "\n",
    "# Compile the Auto Encoder\n",
    "auto_encoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "\n",
    "# Fit the Data on our Auto Encoder\n",
    "log = auto_encoder.fit(X_train_labeled, X_train_labeled, epochs=50, batch_size=256,\n",
    "shuffle=True, validation_data=(X_test_labeled, X_test_labeled))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Fitting of the Auto Encoder is done, we encode the data set with it (reduce its dimentionality to 16)\n",
    "P.S. I decide to reduce the dimentionality of the unlabeled data and then implement clustring algorithm on it to decrease the time of the running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "1313/1313 [==============================] - 4s 3ms/step\n",
      "[[7.4275728e+07 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 7.3842136e+07]\n",
      " [1.8476669e+08 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.8368750e+08]\n",
      " [2.1643147e+08 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.1516738e+08]\n",
      " ...\n",
      " [1.4252397e+08 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.4169155e+08]\n",
      " [1.6324323e+08 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.6228952e+08]\n",
      " [8.5809712e+07 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 8.5308656e+07]]\n",
      "18000\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "encoded_X_train_labeled = encoder.predict(X_train_labeled)\n",
    "encoded_X_test_labeled = encoder.predict(X_test_labeled)\n",
    "encoded_X_train_unlabeled = encoder.predict(X_train_unlabeled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
