{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we load the data and do the pre-processing on it \n",
    "1. check if there is any NULL in the dataset (Because it is the MNIST dataset and it is popular we did not check this part)\n",
    "2. normalize the dataset with z-score and transfer the dataset to the new space with the mean of zero and the standard deviation of 1\n",
    "(Normalizing is not necessary in this project because all the features are in the same range from 0 to 255 but we do not do it here because it cause a problem in the fiting of the autoencoder and it needs integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load the Data Set\n",
    "data_labeled_train = pd.read_csv('labeled_train_set.csv')\n",
    "data_labeled_test = pd.read_csv('test_set.csv')\n",
    "data_unlabeled_train = pd.read_csv('unlabeled_train_set.csv')\n",
    "\n",
    "# Conver the Data Set to Numpy Array and Spliting Labels and Features\n",
    "X_train_labeled = data_labeled_train.iloc[: , 1:].values\n",
    "y_train_labeled = data_labeled_train.iloc[: , 0].values\n",
    "X_test_labeled = data_labeled_test.iloc[: , 1:].values\n",
    "y_test_labeled = data_labeled_test.iloc[: , 0].values\n",
    "X_train_unlabeled = data_unlabeled_train.iloc[:, :].values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build an Auto Encoder and use it for Feature Selection and by that Reduce the dimentionality of the data\n",
    "We are going to implement it in 5 layers: \n",
    "1. Input Layer\n",
    "2. 3 Hidden Layers (128 , 16, 128)\n",
    "3. Output Layer\n",
    "So now it is obvious how the architecture of our Encoder and also Decoder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 7230.7646 - val_loss: 7348.1226\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7229.5332 - val_loss: 7348.1094\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7229.5239 - val_loss: 7348.1030\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7229.5190 - val_loss: 7348.1006\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 7229.5181 - val_loss: 7348.0991\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 7229.5161 - val_loss: 7348.0952\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 7229.5078 - val_loss: 7348.0874\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7229.4761 - val_loss: 7348.0527\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7229.4702 - val_loss: 7348.0518\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 7229.4683 - val_loss: 7348.0503\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 7229.4668 - val_loss: 7348.0479\n",
      "Epoch 12/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 7229.4653 - val_loss: 7348.0454\n",
      "Epoch 13/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7229.4629 - val_loss: 7348.0464\n",
      "Epoch 14/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7229.4595 - val_loss: 7348.0425\n",
      "Epoch 15/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7229.4585 - val_loss: 7348.0400\n",
      "Epoch 16/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 7229.4585 - val_loss: 7348.0391\n",
      "Epoch 17/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 7229.4556 - val_loss: 7348.0386\n",
      "Epoch 18/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7229.4541 - val_loss: 7348.0366\n",
      "Epoch 19/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7229.4517 - val_loss: 7348.0352\n",
      "Epoch 20/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7229.4512 - val_loss: 7348.0352\n",
      "Epoch 21/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7229.3130 - val_loss: 7347.7432\n",
      "Epoch 22/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 7229.1738 - val_loss: 7347.7329\n",
      "Epoch 23/50\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 7229.1177 - val_loss: 7347.6177\n",
      "Epoch 24/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7229.0225 - val_loss: 7347.5103\n",
      "Epoch 25/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7228.9463 - val_loss: 7347.5078\n",
      "Epoch 26/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.9429 - val_loss: 7347.5078\n",
      "Epoch 27/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.9438 - val_loss: 7347.5073\n",
      "Epoch 28/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.9424 - val_loss: 7347.5073\n",
      "Epoch 29/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.9424 - val_loss: 7347.5073\n",
      "Epoch 30/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.9409 - val_loss: 7347.5054\n",
      "Epoch 31/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 7228.9399 - val_loss: 7347.5034\n",
      "Epoch 32/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 7228.8384 - val_loss: 7347.2622\n",
      "Epoch 33/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.6992 - val_loss: 7347.2607\n",
      "Epoch 34/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7228.6978 - val_loss: 7347.2598\n",
      "Epoch 35/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.4839 - val_loss: 7347.0049\n",
      "Epoch 36/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.4409 - val_loss: 7347.0039\n",
      "Epoch 37/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7228.4399 - val_loss: 7347.0039\n",
      "Epoch 38/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.4380 - val_loss: 7347.0024\n",
      "Epoch 39/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.4380 - val_loss: 7347.0015\n",
      "Epoch 40/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 7228.4365 - val_loss: 7347.0000\n",
      "Epoch 41/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7228.4316 - val_loss: 7346.9937\n",
      "Epoch 42/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7228.4297 - val_loss: 7346.9922\n",
      "Epoch 43/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.4282 - val_loss: 7346.9912\n",
      "Epoch 44/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.4268 - val_loss: 7346.9902\n",
      "Epoch 45/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 7228.4238 - val_loss: 7346.9897\n",
      "Epoch 46/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 7228.4243 - val_loss: 7346.9888\n",
      "Epoch 47/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.4233 - val_loss: 7346.9888\n",
      "Epoch 48/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7228.4229 - val_loss: 7346.9873\n",
      "Epoch 49/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7228.4180 - val_loss: 7346.8926\n",
      "Epoch 50/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7228.3267 - val_loss: 7346.8887\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Implimenting the Auto Encoder with the architecture we talked about\n",
    "\n",
    "# Defining the Input Image dimention\n",
    "input_image = keras.Input(shape=(784,))\n",
    "\n",
    "# Define the Encoder\n",
    "encoded = layers.Dense(128, activation='relu')(input_image)\n",
    "encoded = layers.Dense(16, activation='relu')(encoded)\n",
    "\n",
    "# Build the Encoder\n",
    "encoder = keras.Model(input_image, encoded)\n",
    "\n",
    "# Define the Decoder \n",
    "encoded_input = keras.Input(shape=(16,))\n",
    "decoded = layers.Dense(128, activation='relu')(encoded_input)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "# Build the Decoder \n",
    "decoder = keras.Model(encoded_input, decoded)\n",
    "\n",
    "# Build the Auto Encoder\n",
    "auto_encoder = keras.Model(input_image, decoder(encoder(input_image)))\n",
    "\n",
    "# Compile the Auto Encoder\n",
    "auto_encoder.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
    "\n",
    "# Fit the Data on our Auto Encoder\n",
    "log = auto_encoder.fit(X_train_labeled, X_train_labeled, epochs=50, batch_size=256,\n",
    "shuffle=True, validation_data=(X_test_labeled, X_test_labeled))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Fitting of the Auto Encoder is done, we encode the data set with it (reduce its dimentionality to 16)\n",
    "P.S. I decide to reduce the dimentionality of the unlabeled data and then implement clustring algorithm on it to decrease the time of the running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 1ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "1313/1313 [==============================] - 3s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "encoded_X_train_labeled = encoder.predict(X_train_labeled)\n",
    "encoded_X_test_labeled = encoder.predict(X_test_labeled)\n",
    "encoded_X_train_unlabeled = encoder.predict(X_train_unlabeled)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the MLP model, I want to cluster the unlabeled data\n",
    "Clustring Algorithm : K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Build the Model\n",
    "k_means = KMeans(n_clusters=10)\n",
    "\n",
    "# Fit Model on the Unlabeled Data\n",
    "k_means.fit(encoded_X_train_unlabeled)\n",
    "\n",
    "# Get the Labels\n",
    "labels = np.array(k_means.labels_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-processing \n",
    "After the clustering we have to know that which label correspond to which number from 0 to 9,\n",
    "So I decide to get a sample from all of the clusters of size 10 and visually decide which label belongs to which number\n",
    "Also I did not use the decoder to keep my accuracy up and because I had the previous dataset from the begining I used that and just tried to find the indexes in that dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   6  82 253 253 172  44   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  10  25 191 253 252 252 252 197   6\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  30 176 252 252 253 252 252 252 252 134   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  14 214 252 252 252 228 204 234 252\n",
      " 252 180   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  15 173 252 252 252 136  35  18 225 252 252 180   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  61 252 252 252 134   3   0 117\n",
      " 252 252 252  88   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0 158 252 252 220  16   0  51 232 252 252 232  40   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 181 252 252 155   0   0\n",
      " 179 252 252 252 192   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0 181 252 252 243 177 224 253 252 252 252 140   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 124 252 252 252\n",
      " 252 252 253 252 252 148   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  29 213 251 253 253 253 255 253 228  40   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  88 153 238 252 253 252  96   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  42 245 253 249  82   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  73 248 253 228   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109 252 253 228\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  28 207 252 253 228   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  97 252 252\n",
      " 253 187   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  97 252 252 253 108   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 206\n",
      " 252 252 190  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 217 252 252 121   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Get sample from all of the labels of size 10\n",
    "instances_features = []\n",
    "for index in range(10):\n",
    "    count = 0\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == index and count < 10:\n",
    "            instances_features.append(X_train_unlabeled[i])\n",
    "            count += 1\n",
    "\n",
    "\n",
    "# Reshaping the Matrix to prepare it for the image building\n",
    "print(instances_features[0])\n",
    "print(len(instances_features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Pillow Library, I convert the matrixes to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(instances_features[i], mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m img\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m img\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32me:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\PIL\\Image.py:2486\u001b[0m, in \u001b[0;36mImage.show\u001b[1;34m(self, title)\u001b[0m\n\u001b[0;32m   2466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow\u001b[39m(\u001b[39mself\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2467\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2468\u001b[0m \u001b[39m    Displays this image. This method is mainly intended for debugging purposes.\u001b[39;00m\n\u001b[0;32m   2469\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2483\u001b[0m \u001b[39m    :param title: Optional title to use for the image window, where possible.\u001b[39;00m\n\u001b[0;32m   2484\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2486\u001b[0m     _show(\u001b[39mself\u001b[39;49m, title\u001b[39m=\u001b[39;49mtitle)\n",
      "File \u001b[1;32me:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\PIL\\Image.py:3524\u001b[0m, in \u001b[0;36m_show\u001b[1;34m(image, **options)\u001b[0m\n\u001b[0;32m   3521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_show\u001b[39m(image, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions):\n\u001b[0;32m   3522\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageShow\n\u001b[1;32m-> 3524\u001b[0m     ImageShow\u001b[39m.\u001b[39;49mshow(image, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32me:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\PIL\\ImageShow.py:62\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(image, title, **options)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[39mDisplay a given image.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m:returns: ``True`` if a suitable viewer was found, ``False`` otherwise.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m viewer \u001b[39min\u001b[39;00m _viewers:\n\u001b[1;32m---> 62\u001b[0m     \u001b[39mif\u001b[39;00m viewer\u001b[39m.\u001b[39;49mshow(image, title\u001b[39m=\u001b[39;49mtitle, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions):\n\u001b[0;32m     63\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32me:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\PIL\\ImageShow.py:86\u001b[0m, in \u001b[0;36mViewer.show\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39mmode \u001b[39m!=\u001b[39m base:\n\u001b[0;32m     84\u001b[0m         image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mconvert(base)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow_image(image, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32me:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\PIL\\ImageShow.py:112\u001b[0m, in \u001b[0;36mViewer.show_image\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_image\u001b[39m(\u001b[39mself\u001b[39m, image, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions):\n\u001b[0;32m    111\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Display the given image.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow_file(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_image(image), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32me:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\PIL\\ImageShow.py:129\u001b[0m, in \u001b[0;36mViewer.show_file\u001b[1;34m(self, path, **options)\u001b[0m\n\u001b[0;32m    127\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 129\u001b[0m os\u001b[39m.\u001b[39;49msystem(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_command(path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions))  \u001b[39m# nosec\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for i in range(len(instances_features)):\n",
    "    instances_features[i] = np.reshape(instances_features[i],(28, 28))\n",
    "    instances_features[i] = instances_features[i].astype(np.uint8)\n",
    "    img = Image.fromarray(instances_features[i], mode='L')\n",
    "    img.save(f'img{i}.png')\n",
    "    img.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we Have our images and can visually recognize that which label refers to which number \n",
    "label 0 --> number 8\n",
    "label 1 --> number 4\n",
    "label 2 --> number 3\n",
    "label 3 --> number 7\n",
    "label 4 --> number 0\n",
    "label 5 --> number 2\n",
    "label 6 --> number 6\n",
    "label 7 --> number 9\n",
    "label 8 --> number 1\n",
    "label 9 --> number 5\n",
    "\n",
    "P.S. This little Sample did not give me the proper result I had to visuallize more samples from each label but for the report i just show the first 100 instances that was my first sample\n",
    "\n",
    "Post-processing of the clustring is in the below section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the labels to the numbers that belongs to that cluster\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 0:\n",
    "        labels[i] = 8\n",
    "    elif labels[i] == 1:\n",
    "        labels[i] = 4\n",
    "    elif labels[i] == 2:\n",
    "        labels[i] = 3\n",
    "    elif labels[i] == 3:\n",
    "        labels[i] = 7\n",
    "    elif labels[i] == 4:\n",
    "        labels[i] = 0\n",
    "    elif labels[i] == 5:\n",
    "        labels[i] = 2\n",
    "    elif labels[i] == 6:\n",
    "        labels[i] = 6\n",
    "    elif labels[i] == 7:\n",
    "        labels[i] = 9\n",
    "    elif labels[i] == 8:\n",
    "        labels[i] = 1\n",
    "    elif labels[i] == 9:\n",
    "        labels[i] = 5\n",
    "\n",
    "# Combining the datasets\n",
    "X_train_combined = np.concatenate((encoded_X_train_labeled, encoded_X_train_unlabeled), axis=0)\n",
    "y_train_combined = np.concatenate((y_train_labeled, labels), axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the MLP Classifier \n",
    "\n",
    "Now we have all the data (labeled & unlabeled with our labels) and already encoded them into the 16 features space, so every thing is ready to build up the MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.2358\n",
      "\n",
      "Precision : 0.2520675798380682\n",
      "\n",
      "Recall : 0.2358\n",
      "\n",
      "F1 Score : 0.2326139074742693\n",
      "\n",
      "Confusion Matrix : [[367   7  80   8  69 147 135 148  14   5]\n",
      " [  0 420  28 650   0   0  32   3   2   0]\n",
      " [ 24  33 549  29 126  25  98 133  10   5]\n",
      " [ 15 114  95 109 107  94 373  16  49  38]\n",
      " [  6 330 107  68  27  31 110  36  75 192]\n",
      " [ 36  98  86  52  14 202 326  30  31  17]\n",
      " [ 13  10 459  28   1   5 146 292   1   3]\n",
      " [  0 270  11  50   1   4  12  95 268 317]\n",
      " [ 26 120  39  18   5 245 317  20 168  16]\n",
      " [  1 308  12  35   2  24   7  13 332 275]]\n",
      "\n",
      "Fitting Time : 0:07:30.145589\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import datetime\n",
    "\n",
    "# Define a range of choices for each Hyper-Parameter\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100, 100), (50, 100)],\n",
    "    'activation': ['relu', 'logistic'],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "    'batch_size': [32, 64],\n",
    "    'max_iter': [10, 20],}\n",
    "\n",
    "# Create MLp Classifier\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "\n",
    "# Using Five Fold Cross-Validation on our MLP Classifier\n",
    "grid = GridSearchCV(mlp, param_grid=param_grid, cv=5)\n",
    "t1 = datetime.datetime.now()\n",
    "grid.fit(X_train_combined, y_train_combined)\n",
    "t2 = datetime.datetime.now()\n",
    "\n",
    "# Getting the results \n",
    "mlp_best = grid.best_estimator_\n",
    "y_predict = mlp_best.predict(encoded_X_test_labeled)\n",
    "accuracy = accuracy_score(y_test_labeled, y_predict)\n",
    "precision = precision_score(y_test_labeled, y_predict, average='weighted')\n",
    "recall = recall_score(y_test_labeled, y_predict, average='weighted')\n",
    "f1 = f1_score(y_test_labeled, y_predict, average='weighted')\n",
    "conf_mat = confusion_matrix(y_test_labeled, y_predict)\n",
    "fitting_time = t2 - t1\n",
    "\n",
    "# Print the Result\n",
    "print(\"Accuracy : \" + str(accuracy) + \"\\n\")\n",
    "print(\"Precision : \" + str(precision) + \"\\n\")\n",
    "print(\"Recall : \" + str(recall) + \"\\n\")\n",
    "print(\"F1 Score : \" + str(f1) + \"\\n\")\n",
    "print(\"Confusion Matrix : \" + str(conf_mat) + \"\\n\")\n",
    "print(\"Fitting Time : \" + str(fitting_time) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
