{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we load the data and do the pre-processing on it \n",
    "1. check if there is any NULL in the dataset (Because it is the MNIST dataset and it is popular we did not check this part)\n",
    "2. normalize the dataset with z-score and transfer the dataset to the new space with the mean of zero and the standard deviation of 1\n",
    "(Normalizing is not necessary in this project because all the features are in the smae range from 0 to 255 but we do it here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3941638451337934\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load the Data Set\n",
    "data_labeled_train = pd.read_csv('labeled_train_set.csv')\n",
    "data_labeled_test = pd.read_csv('test_set.csv')\n",
    "data_unlabeled_train = pd.read_csv('unlabeled_train_set.csv')\n",
    "\n",
    "# Conver the Data Set to Numpy Array and Spliting Labels and Features\n",
    "X_train_labeled = data_labeled_train.iloc[: , 1:].values\n",
    "y_train_labeled = data_labeled_train.iloc[: , 0].values\n",
    "X_test_labeled = data_labeled_test.iloc[: , 1:].values\n",
    "y_test_labeled = data_labeled_test.iloc[: , 0].values\n",
    "X_train_unlabeled = data_unlabeled_train.iloc[:, :].values\n",
    "\n",
    "# Normalize the Data\n",
    "X_train_labeled = zscore(X_train_labeled)\n",
    "X_test_labeled = zscore(X_test_labeled)\n",
    "X_train_unlabeled = zscore(X_train_unlabeled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build an Auto Encoder and use it for Feature Selection and by that Reduce the dimentionality of the data\n",
    "We are going to implement it in 5 layers: \n",
    "1. Input Layer\n",
    "2. 3 Hidden Layers (128 , 16, 128)\n",
    "3. Output Layer\n",
    "So now it is obvious how the architecture of our Encoder and also Decoder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
