{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we load the data and do the pre-processing on it \n",
    "1. check if there is any NULL in the dataset (Because it is the MNIST dataset and it is popular we did not check this part)\n",
    "2. normalize the dataset with z-score and transfer the dataset to the new space with the mean of zero and the standard deviation of 1\n",
    "(Normalizing is not necessary in this project because all the features are in the same range from 0 to 255 but we do not do it here because it cause a problem in the fiting of the autoencoder and it needs integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load the Data Set\n",
    "data_labeled_train = pd.read_csv('labeled_train_set.csv')\n",
    "data_labeled_test = pd.read_csv('test_set.csv')\n",
    "data_unlabeled_train = pd.read_csv('unlabeled_train_set.csv')\n",
    "\n",
    "# Conver the Data Set to Numpy Array and Spliting Labels and Features\n",
    "X_train_labeled = data_labeled_train.iloc[: , 1:].values\n",
    "y_train_labeled = data_labeled_train.iloc[: , 0].values\n",
    "X_test_labeled = data_labeled_test.iloc[: , 1:].values\n",
    "y_test_labeled = data_labeled_test.iloc[: , 0].values\n",
    "X_train_unlabeled = data_unlabeled_train.iloc[:, :].values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build an Auto Encoder and use it for Feature Selection and by that Reduce the dimentionality of the data\n",
    "We are going to implement it in 5 layers: \n",
    "1. Input Layer\n",
    "2. 3 Hidden Layers (128 , 16, 128)\n",
    "3. Output Layer\n",
    "So now it is obvious how the architecture of our Encoder and also Decoder is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "71/71 [==============================] - 2s 20ms/step - loss: 7231.4326 - val_loss: 7348.8545\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 7230.2241 - val_loss: 7348.8232\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 7230.2070 - val_loss: 7348.8145\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 7230.2026 - val_loss: 7348.8096\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7230.1992 - val_loss: 7348.8066\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7230.1948 - val_loss: 7348.8022\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7230.1899 - val_loss: 7348.7974\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 7230.1880 - val_loss: 7348.7959\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 7230.1855 - val_loss: 7348.7944\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 7230.1816 - val_loss: 7348.7905\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 7230.1782 - val_loss: 7348.7871\n",
      "Epoch 12/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7230.1738 - val_loss: 7348.7847\n",
      "Epoch 13/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7230.1694 - val_loss: 7348.7793\n",
      "Epoch 14/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7230.1675 - val_loss: 7348.7793\n",
      "Epoch 15/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 7230.1665 - val_loss: 7348.7778\n",
      "Epoch 16/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 7230.1636 - val_loss: 7348.7759\n",
      "Epoch 17/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7230.1631 - val_loss: 7348.7744\n",
      "Epoch 18/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7230.1606 - val_loss: 7348.7744\n",
      "Epoch 19/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7230.1592 - val_loss: 7348.7720\n",
      "Epoch 20/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7230.1582 - val_loss: 7348.7705\n",
      "Epoch 21/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7230.1572 - val_loss: 7348.7690\n",
      "Epoch 22/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 7230.1519 - val_loss: 7348.7510\n",
      "Epoch 23/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 7230.1328 - val_loss: 7348.7505\n",
      "Epoch 24/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7230.1318 - val_loss: 7348.7490\n",
      "Epoch 25/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7230.1313 - val_loss: 7348.7471\n",
      "Epoch 26/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7230.1304 - val_loss: 7348.7466\n",
      "Epoch 27/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7230.0435 - val_loss: 7348.6392\n",
      "Epoch 28/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7230.0254 - val_loss: 7348.6392\n",
      "Epoch 29/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7230.0249 - val_loss: 7348.6377\n",
      "Epoch 30/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7230.0229 - val_loss: 7348.6367\n",
      "Epoch 31/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7230.0234 - val_loss: 7348.6377\n",
      "Epoch 32/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 7230.0225 - val_loss: 7348.6362\n",
      "Epoch 33/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 7230.0215 - val_loss: 7348.6343\n",
      "Epoch 34/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7230.0200 - val_loss: 7348.6313\n",
      "Epoch 35/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7230.0200 - val_loss: 7348.6318\n",
      "Epoch 36/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7230.0210 - val_loss: 7348.6318\n",
      "Epoch 37/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7229.9771 - val_loss: 7348.5391\n",
      "Epoch 38/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7229.9233 - val_loss: 7348.5391\n",
      "Epoch 39/50\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 7229.9243 - val_loss: 7348.5366\n",
      "Epoch 40/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7229.9224 - val_loss: 7348.5361\n",
      "Epoch 41/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7229.9209 - val_loss: 7348.5361\n",
      "Epoch 42/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7229.9199 - val_loss: 7348.5342\n",
      "Epoch 43/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7229.9229 - val_loss: 7348.5342\n",
      "Epoch 44/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7229.9204 - val_loss: 7348.5337\n",
      "Epoch 45/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7229.9146 - val_loss: 7348.5327\n",
      "Epoch 46/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7229.9155 - val_loss: 7348.5322\n",
      "Epoch 47/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 7229.9146 - val_loss: 7348.5288\n",
      "Epoch 48/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 7229.9150 - val_loss: 7348.5298\n",
      "Epoch 49/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 7229.9136 - val_loss: 7348.5288\n",
      "Epoch 50/50\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 7229.9111 - val_loss: 7348.5298\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Implimenting the Auto Encoder with the architecture we talked about\n",
    "\n",
    "# Defining the Input Image dimention\n",
    "input_image = keras.Input(shape=(784,))\n",
    "\n",
    "# Define the Encoder\n",
    "encoded = layers.Dense(128, activation='relu')(input_image)\n",
    "encoded = layers.Dense(16, activation='relu')(encoded)\n",
    "\n",
    "# Build the Encoder\n",
    "encoder = keras.Model(input_image, encoded)\n",
    "\n",
    "# Define the Decoder \n",
    "encoded_input = keras.Input(shape=(16,))\n",
    "decoded = layers.Dense(128, activation='relu')(encoded_input)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "# Build the Decoder \n",
    "decoder = keras.Model(encoded_input, decoded)\n",
    "\n",
    "# Build the Auto Encoder\n",
    "auto_encoder = keras.Model(input_image, decoder(encoder(input_image)))\n",
    "\n",
    "# Compile the Auto Encoder\n",
    "auto_encoder.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
    "\n",
    "# Fit the Data on our Auto Encoder\n",
    "log = auto_encoder.fit(X_train_labeled, X_train_labeled, epochs=50, batch_size=256,\n",
    "shuffle=True, validation_data=(X_test_labeled, X_test_labeled))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Fitting of the Auto Encoder is done, we encode the data set with it (reduce its dimentionality to 16)\n",
    "P.S. I decide to reduce the dimentionality of the unlabeled data and then implement clustring algorithm on it to decrease the time of the running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "1313/1313 [==============================] - 4s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "encoded_X_train_labeled = encoder.predict(X_train_labeled)\n",
    "encoded_X_test_labeled = encoder.predict(X_test_labeled)\n",
    "encoded_X_train_unlabeled = encoder.predict(X_train_unlabeled)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the MLP model, I want to cluster the unlabeled data\n",
    "Clustring Algorithm : K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\tuts\\DataMining\\Homeworks\\HW3\\AutoEncoder\\env\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Build the Model\n",
    "k_means = KMeans(n_clusters=10)\n",
    "\n",
    "# Fit Model on the Unlabeled Data\n",
    "k_means.fit(encoded_X_train_unlabeled)\n",
    "\n",
    "# Get the Labels\n",
    "labels = np.array(k_means.labels_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-processing \n",
    "After the clustering we have to know that which label correspond to which number from 0 to 9,\n",
    "So I decide to get a sample from all of the clusters of size 10 and visually decide which label belongs to which number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  39 125 225 254\n",
      " 254 255 254 238 125  51   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 206 253 253 253 253 253 253 253 253 173  51   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38 228 253\n",
      " 253 253 253 253 253 253 253 253 240  51   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  85 253 253 172 119  19  19  39 162 253 253\n",
      " 253 237   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9\n",
      " 132  52   6   0   0   0   0   4 166 253 253 247   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  29\n",
      " 241 253 253 247   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  77 253 253 249  97   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  57  79\n",
      " 166 237 253 253 240   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  19 169 239 253 253 253 253 253 136   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100 253\n",
      " 253 253 253 253 253 253 210   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  54 239 253 253 253 253 253 253 253 250  87\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  58\n",
      " 241 253 253 217 114  88 233 253 253 117   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  94 177  78  24   0  23 224 253\n",
      " 244  36   0   0   0   0   0   0   0   0   0   0   0  18  40   4   0   0\n",
      "   0   0   0   0   0   0   7 134 253 253 220   0   0   0   0   0   0   0\n",
      "   0   0   0   0  16 196 253 172  88   0   0   0   0   0   0  23 134 253\n",
      " 253 234  96   0   0   0   0   0   0   0   0   0   0   0 198 253 253 113\n",
      "  12   0   0   0   0  20  54 224 253 253 250  93   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 170 253 253 110  20  20  20  20  54 227 253 253\n",
      " 253 251 142   0   0   0   0   0   0   0   0   0   0   0   0   0 112 253\n",
      " 253 253 253 253 253 253 253 253 253 253 244 142   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 171 253 253 253 253 253 253 253 253\n",
      " 248 156  39   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  54 123 240 253 253 253 216 123 123  35   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Get sample from all of the labels of size 10\n",
    "instances_features = []\n",
    "for index in range(10):\n",
    "    count = 0\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == index and count < 10:\n",
    "            instances_features.append(X_train_unlabeled[i])\n",
    "            count += 1\n",
    "\n",
    "\n",
    "# Reshaping the Matrix to prepare it for the image building\n",
    "print(instances_features[0])\n",
    "print(len(instances_features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Pillow Library, I convert the matrixes to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for i in range(len(instances_features)):\n",
    "    instances_features[i] = np.reshape(instances_features[i],(28, 28))\n",
    "    instances_features[i] = instances_features[i].astype(np.uint8)\n",
    "    img = Image.fromarray(instances_features[i], mode='L')\n",
    "    img.save(f'img{i}.png')\n",
    "    img.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we Have our images and can visually recognize that which label refers to which number \n",
    "label 0 --> number 8\n",
    "label 1 --> number 4\n",
    "label 2 --> number 3\n",
    "label 3 --> number 7\n",
    "label 4 --> number 0\n",
    "label 5 --> number 2\n",
    "label 6 --> number 6\n",
    "label 7 --> number 9\n",
    "label 8 --> number 1\n",
    "label 9 --> number 5\n",
    "\n",
    "P.S. This little Sample did not give me the proper result I had to visuallize more samples from each label but for the report i just show the first 100 instances that was my first sample\n",
    "\n",
    "Post-processing of the clustring is in the below section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the labels to the numbers that belongs to that cluster\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 0:\n",
    "        labels[i] = 8\n",
    "    elif labels[i] == 1:\n",
    "        labels[i] = 4\n",
    "    elif labels[i] == 2:\n",
    "        labels[i] = 3\n",
    "    elif labels[i] == 3:\n",
    "        labels[i] = 7\n",
    "    elif labels[i] == 4:\n",
    "        labels[i] = 0\n",
    "    elif labels[i] == 5:\n",
    "        labels[i] = 2\n",
    "    elif labels[i] == 6:\n",
    "        labels[i] = 6\n",
    "    elif labels[i] == 7:\n",
    "        labels[i] = 9\n",
    "    elif labels[i] == 8:\n",
    "        labels[i] = 1\n",
    "    elif labels[i] == 9:\n",
    "        labels[i] = 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
